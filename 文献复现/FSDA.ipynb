{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#输入数据\n",
    "f=open('E:\\论文实现\\数据\\phoneme.data')\n",
    "df=pd.read_csv(f)\n",
    "df=df.drop('row.names',1)\n",
    "df_train=df.head(1000)\n",
    "df_test=df[1000:4509]\n",
    "data_train=np.array(df_train)\n",
    "data_test=np.array(df_test)\n",
    "#将数据按类标签分成五类\n",
    "df1=df_train.query('g==\"sh\"')\n",
    "df2=df_train.query('g==\"dcl\"')\n",
    "df3=df_train.query('g==\"iy\"')\n",
    "df4=df_train.query('g==\"aa\"')\n",
    "df5=df_train.query('g==\"ao\"')\n",
    "X_train=np.array(df_train.drop(df_train.columns[[256,257]],1))\n",
    "X_test=np.array(df_test.drop(df_test.columns[[256,257]],1))\n",
    "Y_train=data_train[:,256]\n",
    "Y_test=data_test[:,256]\n",
    "X_sh=np.array(df1.drop(df1.columns[[256,257]],1))\n",
    "X_dcl=np.array(df2.drop(df2.columns[[256,257]],1))\n",
    "X_iy=np.array(df3.drop(df3.columns[[256,257]],1))\n",
    "X_aa=np.array(df4.drop(df4.columns[[256,257]],1))\n",
    "X_ao=np.array(df5.drop(df5.columns[[256,257]],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   32.10001301   106.79397131   312.20008159   691.86048197   286.0402012\n",
      "   143.12096574   229.04272375   356.41780874   347.92652372   393.20276007\n",
      "   453.31201517   489.87306869   414.78572186   461.25726472   598.68778372\n",
      "   670.21439469   801.87736086   930.75678686  1051.73924113   971.02200498\n",
      "  1020.75471759  1061.51952923  1022.49278194   971.12129221   978.37267356\n",
      "   889.47328852   923.35355446  1138.32023034  1087.47922216  1167.38835256\n",
      "   996.78989528  1085.86047165  1132.18816616  1009.23295103   973.14807829\n",
      "   970.00679919   946.48663374   830.83414282   763.04618023   846.89476706\n",
      "   716.62382735   641.35126693   598.24176813   588.34439835   508.50325132\n",
      "   481.4749254    490.90867709   417.70642219   354.64883228   325.37584589\n",
      "   326.73167078   335.19534365   266.08090116   271.5696453    281.72039785\n",
      "   284.67515971   314.74356251   364.08604949   340.31934999   368.34319211\n",
      "   403.47278098   453.59837058   484.66757098   430.21619569   480.48306432\n",
      "   475.95817206   457.02734303   441.87844976   465.85707441   497.14174996\n",
      "   450.10564624   435.20298678   439.86363839   397.83706162   412.96377285\n",
      "   396.32110104   372.23704856   357.87015051   364.24391783   391.37467031\n",
      "   363.04341227   367.47641658   341.36945905   365.89360385   372.92113432\n",
      "   381.85860721   338.9529615    381.49661952   383.63108154   381.59466714\n",
      "   394.87684004   402.70621328   407.47480936   421.32401265   424.74116917\n",
      "   450.2847846    442.24035987   469.98391104   468.82127606   494.38229275\n",
      "   446.2004398    436.27950139   476.73042998   463.99457071   489.16518185\n",
      "   436.67870702   450.07282192   476.75556147   447.74085399   453.31572256\n",
      "   440.59957068   419.53474668   417.81088621   401.07985438   388.52944658\n",
      "   370.89118552   374.38895144   353.21556914   356.63789392   343.70225525\n",
      "   356.55832801   353.84677306   370.20526283   343.91954663   370.17604375\n",
      "   348.08360663   350.19017743   359.51330878   355.88456211   348.82644428\n",
      "   351.73162419   370.98089245   344.09388233   345.47803661   384.34654376\n",
      "   328.57909197   315.85452678   353.72846073   334.76691005   369.19938593\n",
      "   374.73082019   375.90275926   395.31648521   366.29834189   377.71124831\n",
      "   374.72774634   410.08502225   431.87787517   395.98909782   441.41468913\n",
      "   443.03914588   444.9707521    453.38498696   471.2200703    455.71308115\n",
      "   435.56516031   370.95696378   407.82882156   420.28475826   446.88392347\n",
      "   445.91741194   411.9120618    376.20608661   397.44992169   433.13729992\n",
      "   391.2866409    384.72485474   395.59744462   398.30136267   350.71950369\n",
      "   375.95682407   377.02619729   359.91613481   356.78341359   375.16408147\n",
      "   402.57803514   392.98113148   378.28326301   392.24517465   422.20676709\n",
      "   387.48738286   400.37645564   413.43176894   432.38337966   393.29129768\n",
      "   397.48550667   389.5058705    415.2301083    406.51391776   419.81092571\n",
      "   416.6372772    413.18646522   401.88892086   388.85786303   391.22050821\n",
      "   397.37053548   405.88175717   432.8155115    466.62835546   409.09202404\n",
      "   432.60430156   405.40506921   448.55334562   421.86339346   378.37771298\n",
      "   399.15389633   381.21992952   383.59113697   387.51941148   373.12538062\n",
      "   405.34476923   389.9145189    380.2892806    373.77069784   369.81442252\n",
      "   395.6822034    370.40067076   400.94036736   378.66486331   349.40751817\n",
      "   369.24796312   370.13395805   384.01547318   363.04363098   343.62416697\n",
      "   395.8015283    405.04355564   385.01084727   375.32833975   373.7830278\n",
      "   406.42500808   345.45106045   331.83524665   337.9676151    348.17948641\n",
      "   348.51502958   369.14963212   401.36408883   384.70640589   348.43093097\n",
      "   369.87204916   364.09312431   361.58673556   356.21053943   353.83797129\n",
      "   351.74656418   347.03362408   353.47721907   359.96607785   349.63528315\n",
      "   357.56604676   365.17026342   317.64379887   341.18397873   331.39684092\n",
      "   203.60773874]\n"
     ]
    }
   ],
   "source": [
    "#计算F统计量，选出m个h-separared markers\n",
    "X_mean=np.average(X_train,0)\n",
    "X_sh_mean=np.average(X_sh,0)\n",
    "X_dcl_mean=np.average(X_dcl,0)\n",
    "X_iy_mean=np.average(X_iy,0)\n",
    "X_aa_mean=np.average(X_aa,0)\n",
    "X_ao_mean=np.average(X_ao,0)\n",
    "# n1=len(X_sh)\n",
    "# n2=len(X_dcl)\n",
    "# n3=len(X_iy)\n",
    "# n4=len(X_aa)\n",
    "# n5=len(X_ao)\n",
    "Sb=(len(X_sh)*np.square(X_sh_mean-X_mean)+len(X_dcl)*np.square(X_dcl_mean-X_mean)\n",
    "    +len(X_iy)*np.square(X_iy_mean-X_mean)+len(X_aa)*np.square(X_aa_mean-X_mean)\n",
    "    +len(X_ao)*np.square(X_ao_mean-X_mean))/4\n",
    "Sw=(np.var(X_sh,axis=0)*len(X_sh)+np.var(X_dcl,axis=0)*len(X_dcl)\n",
    "    +np.var(X_iy,axis=0)*len(X_iy)+len(X_aa)*np.var(X_aa,axis=0)\n",
    "    +len(X_ao)*np.var(X_ao,axis=0))/(len(X_train)-5)\n",
    "F=Sb/Sw\n",
    "print(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29.  21.  35.   3.  41.  14.  69.]\n"
     ]
    }
   ],
   "source": [
    "#根据m,h选择m个markers\n",
    "def findmarkers(m,h,F):\n",
    "    markers=np.zeros(m)\n",
    "    for i in range(m):\n",
    "        markers[i]=np.argmax(F)\n",
    "        F[max(np.argmax(F)-h,0):min(np.argmax(F)+h,len(F)-1)]=0\n",
    "    return markers\n",
    "m=7\n",
    "h=6\n",
    "markers=findmarkers(m,h,F)\n",
    "print(markers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LDA降维，得到3m个线性判别变量\n",
    "lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "lda.fit(X_train[:,int(max(markers[0]-h,0)):int(min(markers[0]+h,X_train.shape[1]-1))],Y_train)\n",
    "X_train_ldv = lda.transform(X_train[:,int(max(markers[0]-h,0)):int(min(markers[0]+h,X_train.shape[1]-1))])\n",
    "X_test_ldv = lda.transform(X_test[:,int(max(markers[0]-h,0)):int(min(markers[0]+h,X_test.shape[1]-1))])\n",
    "for i in range(1,m):\n",
    "    lda.fit(X_train[:,int(max(markers[i]-h,0)):int(min(markers[i]+h,X_train.shape[1]-1))],Y_train)\n",
    "    X_train_new = lda.transform(X_train[:,int(max(markers[i]-h,0)):int(min(markers[i]+h,X_train.shape[1]-1))])\n",
    "    X_test_new = lda.transform(X_test[:,int(max(markers[i]-h,0)):int(min(markers[i]+h,X_test.shape[1]-1))])\n",
    "    X_train_ldv=np.hstack((X_train_ldv,X_train_new))\n",
    "    X_test_ldv=np.hstack((X_test_ldv,X_test_new))\n",
    "#print(X_ldv)\n",
    "#print(np.shape(X_ldv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964\n",
      "0.914790538615\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf',decision_function_shape='ovo')\n",
    "clf.fit(X_train_ldv, Y_train)\n",
    "print(clf.score(X_train_ldv, Y_train))\n",
    "print(clf.score(X_test_ldv, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
